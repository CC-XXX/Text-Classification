{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6445e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>user_review</th>\n",
       "      <th>user_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>5592</td>\n",
       "      <td>Yu-Gi-Oh! Duel Links</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>unbelievably unbalanced, some cards are game b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>3518</td>\n",
       "      <td>War Thunder</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>---{Graphics}---☐ You forget what reality is☐ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>15513</td>\n",
       "      <td>theHunter Classic</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>The best hunting game around.Some people feel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15431</th>\n",
       "      <td>22866</td>\n",
       "      <td>Crusaders of the Lost Idols</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Unfortunately this game has no real offline pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13645</th>\n",
       "      <td>19589</td>\n",
       "      <td>Creativerse</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Early Access ReviewThis game is lot of fun , i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_id                        title    year  \\\n",
       "4196        5592         Yu-Gi-Oh! Duel Links  2018.0   \n",
       "3054        3518                  War Thunder  2017.0   \n",
       "10105      15513            theHunter Classic  2015.0   \n",
       "15431      22866  Crusaders of the Lost Idols  2017.0   \n",
       "13645      19589                  Creativerse  2016.0   \n",
       "\n",
       "                                             user_review  user_suggestion  \n",
       "4196   unbelievably unbalanced, some cards are game b...                0  \n",
       "3054   ---{Graphics}---☐ You forget what reality is☐ ...                1  \n",
       "10105  The best hunting game around.Some people feel ...                1  \n",
       "15431  Unfortunately this game has no real offline pr...                0  \n",
       "13645  Early Access ReviewThis game is lot of fun , i...                1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from myutils import rule_based_classification\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Game_data/train.csv\")\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d626f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17494 entries, 0 to 17493\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   review_id        17494 non-null  int64  \n",
      " 1   title            17494 non-null  object \n",
      " 2   year             17316 non-null  float64\n",
      " 3   user_review      17494 non-null  object \n",
      " 4   user_suggestion  17494 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 683.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02de705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9968\n",
       "0    7526\n",
       "Name: user_suggestion, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_suggestion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29d4798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 10s 18ms/step - loss: 0.6769 - acc: 0.5961\n",
      "\n",
      "Loss / accuracy on testset: 0.67690509557724 loss / 0.5961472392082214 acc\n",
      "Standard deviation: (+-0.0) loss / (+-0.0) acc\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "from keras.models import load_model\n",
    "from myutils import clean_doc\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "\n",
    "with open('model/tokenizer_cnn.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "\n",
    "X_test, y_test = [clean_doc(x) for x in df['user_review']], df[\"user_suggestion\"]\n",
    "\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_word    = pad_sequences(\n",
    "    sequences_test,\n",
    "    maxlen  = MAX_SEQUENCE_LENGTH,\n",
    "    padding = 'post'\n",
    ")\n",
    "\n",
    "\n",
    "test_loss = []\n",
    "test_accs = []\n",
    "\n",
    "\n",
    "cnn_ = load_model(f\"model_cnn.h5\")\n",
    "score = cnn_.evaluate(X_test_word, to_categorical(y_test), verbose=1)\n",
    "test_loss.append(score[0])\n",
    "test_accs.append(score[1])\n",
    "    \n",
    "print(f\"\\nLoss / accuracy on testset: {np.mean(test_loss)} loss / {np.mean(test_accs)} acc\")\n",
    "print(f\"Standard deviation: (+-{np.std(test_loss)}) loss / (+-{np.std(test_accs)}) acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d70590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improves 0.01\n"
     ]
    }
   ],
   "source": [
    "# add rule_based operation\n",
    "pre_resu_cnn=cnn_.predict(X_test_word, batch_size=30)\n",
    "cnn_impr_result=rule_based_classification(X_test, pre_resu_cnn)\n",
    "print('Accuracy improves %.2f' %cnn_impr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7efe98ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 135s 245ms/step - loss: 0.6912 - acc: 0.5691\n",
      "\n",
      "Loss / accuracy on testset: 0.6911532282829285 loss / 0.5691093802452087 acc\n",
      "Standard deviation: (+-0.0) loss / (+-0.0) acc\n"
     ]
    }
   ],
   "source": [
    "# RNN\n",
    "from keras.models import load_model\n",
    "from myutils import clean_doc\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# evaluation\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "\n",
    "with open('model/tokenizer_rnn.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "X_test, y_test = [clean_doc(x) for x in df['user_review']], df[\"user_suggestion\"]\n",
    "\n",
    "    \n",
    "sequences_test_rn = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_word_rn    = pad_sequences(\n",
    "    sequences_test_rn,\n",
    "    maxlen  = MAX_SEQUENCE_LENGTH,\n",
    "    padding = 'post'\n",
    ")\n",
    "\n",
    "\n",
    "test_loss = []\n",
    "test_accs = []\n",
    "\n",
    "\n",
    "rnn_ = load_model(f\"model_rnn.h5\")\n",
    "score = rnn_.evaluate(X_test_word_rn, to_categorical(y_test), verbose=1)\n",
    "test_loss.append(score[0])\n",
    "test_accs.append(score[1])\n",
    "    \n",
    "print(f\"\\nLoss / accuracy on testset: {np.mean(test_loss)} loss / {np.mean(test_accs)} acc\")\n",
    "print(f\"Standard deviation: (+-{np.std(test_loss)}) loss / (+-{np.std(test_accs)}) acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f0117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improves 0.05\n"
     ]
    }
   ],
   "source": [
    "# add rule_based operation\n",
    "pre_resu_rnn=rnn_.predict(X_test_word_rn, batch_size=30)\n",
    "rnn_impr_result=rule_based_classification(X_test, pre_resu_rnn)\n",
    "print(\"Accuracy improves %.2f\" %rnn_impr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3aeb779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 70s 125ms/step - loss: 0.5671 - acc: 0.7036\n",
      "\n",
      "Loss / accuracy on testset: 0.5670555233955383 loss / 0.7036126852035522 acc\n",
      "Standard deviation: (+-0.0) loss / (+-0.0) acc\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from myutils import clean_doc, clean_doc_HAN\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "# evaluation\n",
    "\n",
    "MAX_SENTS = 15\n",
    "MAX_SENT_LENGTH = 100\n",
    "MAX_NB_WORDS = 15000\n",
    "\n",
    "\n",
    "with open('model/tokenizer_han.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "X_test, y_test = [clean_doc(x) for x in df['user_review']], df[\"user_suggestion\"]\n",
    "\n",
    "sequences_test_han = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "data_test_han = np.zeros((len(X_test), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "reviews=[]\n",
    "\n",
    "for x in X_test:\n",
    "    #print(clean_doc_HAN(x.decode()))\n",
    "    reviews.append(clean_doc_HAN(x))\n",
    "\n",
    "for i, sentences in enumerate(reviews):\n",
    "    #print(sentences)\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j< MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if word in tokenizer.word_index.keys():\n",
    "                    if k<MAX_SENT_LENGTH and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                        data_test_han[i,j,k] = tokenizer.word_index[word]\n",
    "                        k=k+1\n",
    "\n",
    "X_test_word_han=data_test_han\n",
    "\n",
    "test_loss = []\n",
    "test_accs = []\n",
    "\n",
    "\n",
    "han_ = load_model(f\"model_han_.h5\")\n",
    "score = han_.evaluate(X_test_word_han, to_categorical(y_test), verbose=1)\n",
    "test_loss.append(score[0])\n",
    "test_accs.append(score[1])\n",
    "    \n",
    "print(f\"\\nLoss / accuracy on testset: {np.mean(test_loss)} loss / {np.mean(test_accs)} acc\")\n",
    "print(f\"Standard deviation: (+-{np.std(test_loss)}) loss / (+-{np.std(test_accs)}) acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b2bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improves 0.02\n"
     ]
    }
   ],
   "source": [
    "# add rule_based operation\n",
    "pre_resu_han=han_.predict(X_test_word_han, batch_size=30)\n",
    "han_impr_result=rule_based_classification(X_test, pre_resu_han)\n",
    "print(\"Accuracy improves %.2f\" %han_impr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22d5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
